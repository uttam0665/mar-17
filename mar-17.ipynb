{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from imblearn.combine import SMOTEENN\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Create a Jupyter Notebook\n",
    "nb = nbf.v4.new_notebook()\n",
    "\n",
    "# Add a title cell\n",
    "nb.cells.append(nbf.v4.new_markdown_cell(\"# Data Science Masters Assignment\"))\n",
    "\n",
    "# Add an introduction cell\n",
    "nb.cells.append(nbf.v4.new_markdown_cell(\"## Feature Engineering-1\"))\n",
    "\n",
    "# Q1: Missing Values in a Dataset\n",
    "nb.cells.append(nbf.v4.new_markdown_cell(\"### Q1: What are missing values in a dataset? Why is it essential to handle missing values? Name some algorithms that are not affected by missing values.\"))\n",
    "nb.cells.append(nbf.v4.new_markdown_cell(\"\"\"\n",
    "Missing values are the data points that are not stored in the dataset due to various reasons such as data corruption, data entry errors, or data unavailability. \n",
    "\n",
    "It is essential to handle missing values because they can lead to incorrect analysis and misleading conclusions. Algorithms such as decision trees and k-nearest neighbors (KNN) are not affected by missing values.\n",
    "\"\"\"))\n",
    "\n",
    "# Q2: Techniques to Handle Missing Data\n",
    "nb.cells.append(nbf.v4.new_markdown_cell(\"### Q2: List down techniques used to handle missing data. Give an example of each with python code.\"))\n",
    "nb.cells.append(nbf.v4.new_code_cell(\"\"\"\n",
    "# Importing libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Creating a sample dataframe with missing values\n",
    "data = {'A': [1, 2, np.nan, 4, 5], 'B': [5, np.nan, np.nan, 8, 10], 'C': [10, 11, 12, 13, np.nan]}\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Technique 1: Removing rows with missing values\n",
    "df_dropped = df.dropna()\n",
    "print(\"Data after removing rows with missing values:\\\\n\", df_dropped)\n",
    "\n",
    "# Technique 2: Imputing missing values with mean\n",
    "imputer = SimpleImputer(strategy='mean')\n",
    "df_imputed = pd.DataFrame(imputer.fit_transform(df), columns=df.columns)\n",
    "print(\"Data after imputing missing values with mean:\\\\n\", df_imputed)\n",
    "\"\"\"))\n",
    "\n",
    "# Q3: Explain the imbalanced data\n",
    "nb.cells.append(nbf.v4.new_markdown_cell(\"### Q3: Explain the imbalanced data. What will happen if imbalanced data is not handled?\"))\n",
    "nb.cells.append(nbf.v4.new_markdown_cell(\"\"\"\n",
    "Imbalanced data occurs when the classes in a dataset are not represented equally. For example, in a binary classification problem, if one class constitutes 90% of the data and the other class only 10%, the data is imbalanced. \n",
    "\n",
    "If imbalanced data is not handled, the machine learning model may become biased towards the majority class and perform poorly on the minority class.\n",
    "\"\"\"))\n",
    "\n",
    "# Q4: Up-sampling and Down-sampling\n",
    "nb.cells.append(nbf.v4.new_markdown_cell(\"### Q4: What are Up-sampling and Down-sampling? Explain with an example when up-sampling and down-sampling are required.\"))\n",
    "nb.cells.append(nbf.v4.new_code_cell(\"\"\"\n",
    "# Importing libraries\n",
    "from sklearn.utils import resample\n",
    "\n",
    "# Creating a sample dataset\n",
    "data = {'feature': [1, 2, 3, 4, 5, 6, 7, 8, 9, 10], 'class': [0, 0, 0, 0, 0, 1, 1, 1, 1, 1]}\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Down-sampling majority class\n",
    "df_majority = df[df['class'] == 0]\n",
    "df_minority = df[df['class'] == 1]\n",
    "df_majority_downsampled = resample(df_majority, replace=False, n_samples=len(df_minority), random_state=42)\n",
    "df_downsampled = pd.concat([df_majority_downsampled, df_minority])\n",
    "print(\"Data after down-sampling:\\\\n\", df_downsampled)\n",
    "\n",
    "# Up-sampling minority class\n",
    "df_minority_upsampled = resample(df_minority, replace=True, n_samples=len(df_majority), random_state=42)\n",
    "df_upsampled = pd.concat([df_majority, df_minority_upsampled])\n",
    "print(\"Data after up-sampling:\\\\n\", df_upsampled)\n",
    "\"\"\"))\n",
    "\n",
    "# Q5: Data Augmentation and SMOTE\n",
    "nb.cells.append(nbf.v4.new_markdown_cell(\"### Q5: What is data Augmentation? Explain SMOTE.\"))\n",
    "nb.cells.append(nbf.v4.new_markdown_cell(\"\"\"\n",
    "Data augmentation is a technique to increase the diversity of training data without collecting new data by applying random transformations like rotation, flipping, etc.\n",
    "\n",
    "SMOTE (Synthetic Minority Over-sampling Technique) is a technique to generate synthetic samples for the minority class to balance the class distribution.\n",
    "\"\"\"))\n",
    "\n",
    "# Q6: Outliers in a Dataset\n",
    "nb.cells.append(nbf.v4.new_markdown_cell(\"### Q6: What are outliers in a dataset? Why is it essential to handle outliers?\"))\n",
    "nb.cells.append(nbf.v4.new_markdown_cell(\"\"\"\n",
    "Outliers are data points that significantly differ from other observations. They can skew the results and affect the performance of machine learning models. Handling outliers is essential to improve the accuracy and reliability of the analysis.\n",
    "\"\"\"))\n",
    "\n",
    "# Q7: Techniques to Handle Missing Data in Analysis\n",
    "nb.cells.append(nbf.v4.new_markdown_cell(\"### Q7: You are working on a project that requires analyzing customer data. However, you notice that some of the data is missing. What are some techniques you can use to handle the missing data in your analysis?\"))\n",
    "nb.cells.append(nbf.v4.new_markdown_cell(\"\"\"\n",
    "Techniques to handle missing data:\n",
    "1. Remove rows/columns with missing values\n",
    "2. Impute missing values with mean/median/mode\n",
    "3. Use machine learning algorithms that can handle missing values\n",
    "4. Predict missing values using other features\n",
    "\"\"\"))\n",
    "\n",
    "# Q8: Strategies to Determine Missing Data Patterns\n",
    "nb.cells.append(nbf.v4.new_markdown_cell(\"### Q8: You are working with a large dataset and find that a small percentage of the data is missing. What are some strategies you can use to determine if the missing data is missing at random or if there is a pattern to the missing data?\"))\n",
    "nb.cells.append(nbf.v4.new_markdown_cell(\"\"\"\n",
    "Strategies to determine missing data patterns:\n",
    "1. Visualize missing data with heatmaps or missing data matrices\n",
    "2. Perform statistical tests to analyze the randomness of missing data\n",
    "3. Check correlation between missing data and other features\n",
    "\"\"\"))\n",
    "\n",
    "# Q9: Evaluating Model Performance on Imbalanced Data\n",
    "nb.cells.append(nbf.v4.new_markdown_cell(\"### Q9: Suppose you are working on a medical diagnosis project and find that the majority of patients in the dataset do not have the condition of interest, while a small percentage do. What are some strategies you can use to evaluate the performance of your machine learning model on this imbalanced dataset?\"))\n",
    "nb.cells.append(nbf.v4.new_markdown_cell(\"\"\"\n",
    "Strategies to evaluate model performance on imbalanced data:\n",
    "1. Use precision-recall curve instead of ROC curve\n",
    "2. Calculate F1-score, which considers both precision and recall\n",
    "3. Use confusion matrix to understand the true positives, false positives, true negatives, and false negatives\n",
    "\"\"\"))\n",
    "\n",
    "# Q10: Methods to Balance Dataset by Down-sampling\n",
    "nb.cells.append(nbf.v4.new_markdown_cell(\"### Q10: When attempting to estimate customer satisfaction for a project, you discover that the dataset is unbalanced, with the bulk of customers reporting being satisfied. What methods can you employ to balance the dataset and down-sample the majority class?\"))\n",
    "nb.cells.append(nbf.v4.new_markdown_cell(\"\"\"\n",
    "Methods to balance dataset by down-sampling:\n",
    "1. Random under-sampling: Randomly remove samples from the majority class\n",
    "2. Cluster-based under-sampling: Use clustering algorithms to identify and remove redundant samples from the majority class\n",
    "\"\"\"))\n",
    "\n",
    "# Q11: Methods to Balance Dataset by Up-sampling\n",
    "nb.cells.append(nbf.v4.new_markdown_cell(\"### Q11: You discover that the dataset is unbalanced with a low percentage of occurrences while working on a project that requires you to estimate the occurrence of a rare event. What methods can you employ to balance the\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
